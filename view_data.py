"""
NICL í”„ë¡œì íŠ¸ - ë°ì´í„° ì¡°íšŒ ìŠ¤í¬ë¦½íŠ¸
ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ í™•ì¸í•˜ëŠ” ìœ í‹¸ë¦¬í‹°
"""

import os
import sys
import sqlite3
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
DB_PATH = os.path.join(project_root, 'data', 'nicl_news.db')

def connect_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
    if not os.path.exists(DB_PATH):
        print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DB_PATH}")
        print("ë¨¼ì € ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•´ì£¼ì„¸ìš”.")
        return None
    
    return sqlite3.connect(DB_PATH)

def view_all_news(limit=10):
    """ëª¨ë“  ë‰´ìŠ¤ ì¡°íšŒ"""
    conn = connect_db()
    if not conn:
        return
    
    cursor = conn.cursor()
    
    # ìµœê·¼ ë‰´ìŠ¤ ì¡°íšŒ
    cursor.execute("""
        SELECT id, title, keyword, pub_date, created_at, source
        FROM news_articles
        ORDER BY created_at DESC
        LIMIT ?
    """, (limit,))
    
    news_list = cursor.fetchall()
    
    print("=" * 80)
    print(f"ğŸ“° ìµœê·¼ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ (ìµœëŒ€ {limit}ê°œ)")
    print("=" * 80)
    
    if not news_list:
        print("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for i, news in enumerate(news_list, 1):
            news_id, title, keyword, pub_date, created_at, source = news
            print(f"\n[{i}] ID: {news_id}")
            print(f"ì œëª©: {title}")
            print(f"í‚¤ì›Œë“œ: {keyword}")
            print(f"ë°œí–‰ì¼: {pub_date}")
            print(f"ìˆ˜ì§‘ì¼: {created_at}")
            print(f"ì¶œì²˜: {source}")
            print("-" * 80)
    
    conn.close()

def view_news_by_keyword(keyword):
    """í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ì¡°íšŒ"""
    conn = connect_db()
    if not conn:
        return
    
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT id, title, description, pub_date, link
        FROM news_articles
        WHERE keyword = ?
        ORDER BY created_at DESC
    """, (keyword,))
    
    news_list = cursor.fetchall()
    
    print("=" * 80)
    print(f"ğŸ“° '{keyword}' í‚¤ì›Œë“œ ë‰´ìŠ¤ ({len(news_list)}ê°œ)")
    print("=" * 80)
    
    if not news_list:
        print(f"'{keyword}' í‚¤ì›Œë“œë¡œ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        for i, news in enumerate(news_list, 1):
            news_id, title, description, pub_date, link = news
            print(f"\n[{i}] ID: {news_id}")
            print(f"ì œëª©: {title}")
            print(f"ìš”ì•½: {description[:100]}..." if description else "ìš”ì•½: ì—†ìŒ")
            print(f"ë°œí–‰ì¼: {pub_date}")
            print(f"ë§í¬: {link}")
            print("-" * 80)
    
    conn.close()

def view_statistics():
    """í†µê³„ ì¡°íšŒ"""
    conn = connect_db()
    if not conn:
        return
    
    cursor = conn.cursor()
    
    # ì „ì²´ í†µê³„
    cursor.execute("SELECT COUNT(*) FROM news_articles")
    total = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM news_articles WHERE is_duplicate = 1")
    duplicates = cursor.fetchone()[0]
    
    # í‚¤ì›Œë“œë³„ í†µê³„
    cursor.execute("""
        SELECT keyword, COUNT(*) as count
        FROM news_articles
        WHERE is_duplicate = 0
        GROUP BY keyword
        ORDER BY count DESC
    """)
    keyword_stats = cursor.fetchall()
    
    # ë‚ ì§œë³„ í†µê³„
    cursor.execute("""
        SELECT DATE(created_at) as date, COUNT(*) as count
        FROM news_articles
        GROUP BY DATE(created_at)
        ORDER BY date DESC
        LIMIT 7
    """)
    date_stats = cursor.fetchall()
    
    print("=" * 80)
    print("ğŸ“Š NICL ë°ì´í„°ë² ì´ìŠ¤ í†µê³„")
    print("=" * 80)
    
    print(f"\nğŸ“° ì „ì²´ ë‰´ìŠ¤")
    print(f"  - ì´ ë‰´ìŠ¤: {total:,}ê°œ")
    print(f"  - ê³ ìœ  ë‰´ìŠ¤: {total - duplicates:,}ê°œ")
    print(f"  - ì¤‘ë³µ ë‰´ìŠ¤: {duplicates:,}ê°œ")
    
    if keyword_stats:
        print(f"\nğŸ” í‚¤ì›Œë“œë³„ í†µê³„ (ì¤‘ë³µ ì œì™¸)")
        for keyword, count in keyword_stats:
            print(f"  - {keyword}: {count:,}ê°œ")
    
    if date_stats:
        print(f"\nğŸ“… ìµœê·¼ 7ì¼ ìˆ˜ì§‘ í˜„í™©")
        for date, count in date_stats:
            print(f"  - {date}: {count:,}ê°œ")
    
    conn.close()

def view_detailed_news(news_id):
    """íŠ¹ì • ë‰´ìŠ¤ ìƒì„¸ ì¡°íšŒ"""
    conn = connect_db()
    if not conn:
        return
    
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT *
        FROM news_articles
        WHERE id = ?
    """, (news_id,))
    
    news = cursor.fetchone()
    
    if not news:
        print(f"ID {news_id}ì¸ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        columns = [desc[0] for desc in cursor.description]
        print("=" * 80)
        print(f"ğŸ“° ë‰´ìŠ¤ ìƒì„¸ ì •ë³´ (ID: {news_id})")
        print("=" * 80)
        
        for col, val in zip(columns, news):
            print(f"{col}: {val}")
    
    conn.close()

def export_to_csv(filename='nicl_news_export.csv'):
    """CSVë¡œ ë‚´ë³´ë‚´ê¸°"""
    conn = connect_db()
    if not conn:
        return
    
    import csv
    
    cursor = conn.cursor()
    cursor.execute("""
        SELECT id, title, original_link, description, pub_date, keyword, category, created_at
        FROM news_articles
        WHERE is_duplicate = 0
        ORDER BY created_at DESC
    """)
    
    news_list = cursor.fetchall()
    
    if not news_list:
        print("ë‚´ë³´ë‚¼ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # CSV íŒŒì¼ ìƒì„±
    csv_path = os.path.join(project_root, filename)
    
    with open(csv_path, 'w', newline='', encoding='utf-8-sig') as f:
        writer = csv.writer(f)
        
        # í—¤ë”
        writer.writerow(['ID', 'ì œëª©', 'ë§í¬', 'ìš”ì•½', 'ë°œí–‰ì¼', 'í‚¤ì›Œë“œ', 'ì¹´í…Œê³ ë¦¬', 'ìˆ˜ì§‘ì¼'])
        
        # ë°ì´í„°
        writer.writerows(news_list)
    
    print(f"âœ… CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {csv_path}")
    print(f"ì´ {len(news_list):,}ê°œì˜ ë‰´ìŠ¤ ë°ì´í„°")
    
    conn.close()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='NICL ë°ì´í„° ì¡°íšŒ')
    parser.add_argument('--all', '-a', action='store_true', help='ëª¨ë“  ë‰´ìŠ¤ ì¡°íšŒ')
    parser.add_argument('--limit', '-l', type=int, default=10, help='ì¡°íšŒí•  ë‰´ìŠ¤ ê°œìˆ˜')
    parser.add_argument('--keyword', '-k', type=str, help='í‚¤ì›Œë“œë³„ ë‰´ìŠ¤ ì¡°íšŒ')
    parser.add_argument('--stats', '-s', action='store_true', help='í†µê³„ ì¡°íšŒ')
    parser.add_argument('--detail', '-d', type=int, help='ë‰´ìŠ¤ ìƒì„¸ ì¡°íšŒ (ID)')
    parser.add_argument('--export', '-e', action='store_true', help='CSVë¡œ ë‚´ë³´ë‚´ê¸°')
    
    args = parser.parse_args()
    
    if len(sys.argv) == 1:
        # ê¸°ë³¸: í†µê³„ ë³´ê¸°
        view_statistics()
    elif args.all:
        view_all_news(args.limit)
    elif args.keyword:
        view_news_by_keyword(args.keyword)
    elif args.stats:
        view_statistics()
    elif args.detail:
        view_detailed_news(args.detail)
    elif args.export:
        export_to_csv()
    else:
        parser.print_help()

if __name__ == "__main__":
    main()